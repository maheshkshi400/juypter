{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a55b71a-d28d-42a1-9f03-64d9bf37b79f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3176613425.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    from delta.tables import DeltaTable\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    " from delta.tables import DeltaTable\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"https://github.com/maheshkshi400/MK\").getOrCreate()\n",
    "\n",
    "from delta.tables import *\n",
    "# create delta tables\n",
    "# Method 1\n",
    "DeltaTable.create(spark)\\\n",
    "    .tableName(\"employee_demo\")\\\n",
    "    .addColumn(\"emp_id\",\"INT\")\\\n",
    "    .addColumn(\"emp_name\",\"STRING\")\\\n",
    "    .addColumn(\"emp_gender\",\"STRING\")\\\n",
    "    .addColumn(\"emp_salary\",\"INT\")\\\n",
    "    .addColumn(\"emp_dept\",\"STRING\")\\\n",
    "    .property(\"discription\",\"table created for demo purpose\")\\\n",
    "    .location(\"C:/Users/Pc/juypter/createtable\")\\\n",
    "    .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c45b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from employee_demo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f1c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "# create delta tables\n",
    "\n",
    "#Method 2\n",
    "DeltaTable.createIfNotExists(spark)\\\n",
    "    .tableName(\"employee_demo\")\\\n",
    "    .addColumn(\"emp_id\",\"INT\")\\\n",
    "    .addColumn(\"emp_name\",\"STRING\")\\\n",
    "    .addColumn(\"emp_gender\",\"STRING\")\\\n",
    "    .addColumn(\"emp_salary\",\"INT\")\\\n",
    "    .addColumn(\"emp_dept\",\"STRING\")\\\n",
    "    .property(\"discription\",\"table created for demo purpose\")\\\n",
    "    .location(\"/FileStore/tables/delta/createtable\")\\\n",
    "    .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "# create delta tables\n",
    "\n",
    "# Method 3\n",
    "\n",
    "DeltaTable.createOrReplace(spark)\\\n",
    "    .tableName(\"employee_demo\")\\\n",
    "    .addColumn(\"emp_id\",\"INT\")\\\n",
    "    .addColumn(\"emp_name\",\"STRING\")\\\n",
    "    .addColumn(\"emp_gender\",\"STRING\")\\\n",
    "    .addColumn(\"emp_salary\",\"INT\")\\\n",
    "    .addColumn(\"emp_dept\",\"STRING\")\\\n",
    "    .property(\"discription\",\"table created for demo purpose\")\\\n",
    "    .location(\"/FileStore/tables/delta/createtable\")\\\n",
    "    .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "# create delta tables\n",
    "\n",
    "# Method 4\n",
    "\n",
    "DeltaTable.create(spark)\\\n",
    "    .tableName(\"default.employee_demo\")\\\n",
    "    .addColumn(\"emp_id\",\"INT\")\\\n",
    "    .addColumn(\"emp_name\",\"STRING\")\\\n",
    "    .addColumn(\"emp_gender\",\"STRING\")\\\n",
    "    .addColumn(\"emp_salary\",\"INT\")\\\n",
    "    .addColumn(\"emp_dept\",\"STRING\")\\\n",
    "    .property(\"discription\",\"table created for demo purpose\")\\\n",
    "    .location(\"/FileStore/tables/delta/createtable\")\\\n",
    "    .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad21fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method -SQL Approach\n",
    "\n",
    "%sql\n",
    "CREATE TABLE employee_demo(\n",
    "    emp_id  INT,\n",
    "    emp_name  String,\n",
    "    emp_gender STRING,\n",
    "    emp_salary INT,\n",
    "    emp_dept STRING,\n",
    ") USING DELTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e4768",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS employee_demo(\n",
    "    emp_id  INT,\n",
    "    emp_name  String,\n",
    "    emp_gender STRING,\n",
    "    emp_salary INT,\n",
    "    emp_dept STRING,\n",
    ") USING DELTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28bcc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+------------------+\n",
      "| Name|           Array_1|           Array_2|\n",
      "+-----+------------------+------------------+\n",
      "| John|   [4, 6, 7, 9, 2]|   [1, 2, 3, 7, 7]|\n",
      "|David|[7, 5, 1, 4, 7, 1]|[3, 2, 8, 9, 4, 9]|\n",
      "| Mike|   [3, 9, 1, 6, 2]|   [1, 2, 3, 5, 8]|\n",
      "+-----+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 56824)\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\anaconda\\Lib\\socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"e:\\anaconda\\Lib\\socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"e:\\anaconda\\Lib\\socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"e:\\anaconda\\Lib\\socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"e:\\anaconda\\Lib\\site-packages\\pyspark\\accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"e:\\anaconda\\Lib\\site-packages\\pyspark\\accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"e:\\anaconda\\Lib\\site-packages\\pyspark\\accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda\\Lib\\site-packages\\pyspark\\serializers.py\", line 594, in read_int\n",
      "    length = stream.read(4)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"e:\\anaconda\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"https://github.com/maheshkshi400/MK\").getOrCreate()\n",
    "\n",
    "empdf= [\n",
    "    ('John',[4,6,7,9,2],[1,2,3,7,7]),\n",
    "    ('David',[7,5,1,4,7,1],[3,2,8,9,4,9]),\n",
    "    ('Mike',[3,9,1,6,2],[1,2,3,5,8])\n",
    "]\n",
    "\n",
    "\n",
    "array_schema=[\"Name\",\"Array_1\",\"Array_2\"]\n",
    "\n",
    "df1= spark.createDataFrame(data=empdf,schema=array_schema)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f676e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table in metastrore ising dataframes schema and write data to it.\n",
    "\n",
    "df.write.format(\"delta\").saveAsTable(default.employee_demo1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
