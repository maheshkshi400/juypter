{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'JavaPackage' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 38\u001b[0m\n\u001b[0;32m     28\u001b[0m schema1 \u001b[38;5;241m=\u001b[39m StructType([\n\u001b[0;32m     29\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, StringType(), \u001b[38;5;28;01mTrue\u001b[39;00m),  \u001b[38;5;66;03m# String for name\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m\"\u001b[39m, StringType(), \u001b[38;5;28;01mTrue\u001b[39;00m),  \u001b[38;5;66;03m# String for gender\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattendance\u001b[39m\u001b[38;5;124m\"\u001b[39m, IntegerType(), \u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Integer for attendance\u001b[39;00m\n\u001b[0;32m     35\u001b[0m ])\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Create DataFrame with schema\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m studf \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_student\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Show the DataFrame\u001b[39;00m\n\u001b[0;32m     41\u001b[0m studf\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\sql\\session.py:1443\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[0;32m   1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SparkSession, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreateDataFrame(  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m   1441\u001b[0m         data, schema, samplingRatio, verifySchema\n\u001b[0;32m   1442\u001b[0m     )\n\u001b[1;32m-> 1443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\sql\\session.py:1487\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m   1485\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_createFromLocal(\u001b[38;5;28mmap\u001b[39m(prepare, data), schema)\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1487\u001b[0m jrdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mSerDeUtil\u001b[38;5;241m.\u001b[39mtoJavaArray(\u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_java_object_rdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1488\u001b[0m jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsparkSession\u001b[38;5;241m.\u001b[39mapplySchemaToPythonRDD(jrdd\u001b[38;5;241m.\u001b[39mrdd(), struct\u001b[38;5;241m.\u001b[39mjson())\n\u001b[0;32m   1489\u001b[0m df \u001b[38;5;241m=\u001b[39m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\rdd.py:4918\u001b[0m, in \u001b[0;36mRDD._to_java_object_rdd\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4915\u001b[0m rdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pickled()\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 4918\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mSerDeUtil\u001b[38;5;241m.\u001b[39mpythonToJava(\u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\rdd.py:5470\u001b[0m, in \u001b[0;36mPipelinedRDD._jrdd\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5467\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5468\u001b[0m     profiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 5470\u001b[0m wrapped_func \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5471\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prev_jrdd_deserializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd_deserializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofiler\u001b[49m\n\u001b[0;32m   5472\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5474\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   5475\u001b[0m python_rdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonRDD(\n\u001b[0;32m   5476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prev_jrdd\u001b[38;5;241m.\u001b[39mrdd(), wrapped_func, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreservesPartitioning, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_barrier\n\u001b[0;32m   5477\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\rdd.py:5270\u001b[0m, in \u001b[0;36m_wrap_function\u001b[1;34m(sc, func, deserializer, serializer, profiler)\u001b[0m\n\u001b[0;32m   5268\u001b[0m pickled_command, broadcast_vars, env, includes \u001b[38;5;241m=\u001b[39m _prepare_for_python_RDD(sc, command)\n\u001b[0;32m   5269\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 5270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSimplePythonFunction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mbytearray\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpickled_command\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5272\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mincludes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5274\u001b[0m \u001b[43m    \u001b[49m\u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpythonExec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5275\u001b[0m \u001b[43m    \u001b[49m\u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpythonVer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbroadcast_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5277\u001b[0m \u001b[43m    \u001b[49m\u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_javaAccumulator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5278\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'JavaPackage' object is not callable"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession with a proper application name\n",
    "spark = SparkSession.builder.appName(\"StudentDataFrame\").getOrCreate()\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Sample student data\n",
    "data_student = [\n",
    "    ('mahesh', 'Male', 'Physics', 80, 'P', 90),\n",
    "    ('mahesh', 'Male', 'Chemistry', 67, 'P', 90),\n",
    "    ('mahesh', 'Male', 'Mathematics', 67, 'P', 90),\n",
    "    ('Shruthi', 'Female', 'Physics', 60, 'P', 86),\n",
    "    ('shruthi', 'female', 'Chemistry', 67, 'P', 86),\n",
    "    ('shruthi', 'female', 'Mathematics', 52, 'P', 86),\n",
    "    ('Prachi', 'female', 'Physics', 72, 'P', 72),\n",
    "    ('Prachi', 'female', 'Chemistry', 80, 'P', 72),\n",
    "    ('Prachi', 'female', 'Mathematics', 90, 'P', 72),\n",
    "    ('Vaishanavi', 'female', 'Physics', 50, 'P', 70),\n",
    "    ('Vaishanavi', 'female', 'Chemistry', 86, 'P', 70),\n",
    "    ('Vaishanavi', 'female', 'Mathematics', 70, 'P', 70),\n",
    "    ('Avanti', 'female', 'Physics', 77, 'P', 90),\n",
    "    ('Avanti', 'female', 'Chemistry', 95, 'P', 90),\n",
    "    ('Avanti', 'female', 'Mathematics', 78, 'P', 90)\n",
    "]\n",
    "\n",
    "# Define schema using StructField for explicit data types\n",
    "schema1 = StructType([\n",
    "    StructField(\"name\", StringType(), True),  # String for name\n",
    "    StructField(\"gender\", StringType(), True),  # String for gender\n",
    "    StructField(\"subject\", StringType(), True),  # String for subject\n",
    "    StructField(\"mark\", IntegerType(), True),  # Integer for mark\n",
    "    StructField(\"status\", StringType(), True),  # String for status\n",
    "    StructField(\"attendance\", IntegerType(), True)  # Integer for attendance\n",
    "])\n",
    "\n",
    "# Create DataFrame with schema\n",
    "studf = spark.createDataFrame(data_student, schema1)\n",
    "\n",
    "# Show the DataFrame\n",
    "studf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-----------+----+------+----------+---+\n",
      "|      name|gender|    subject|mark|status|attendance|row|\n",
      "+----------+------+-----------+----+------+----------+---+\n",
      "|    Avanti|female|  Chemistry|  95|     P|        90|  1|\n",
      "|    Avanti|female|Mathematics|  78|     P|        90|  2|\n",
      "|    Avanti|female|    Physics|  77|     P|        90|  3|\n",
      "|    Prachi|female|Mathematics|  90|     P|        72|  1|\n",
      "|    Prachi|female|  chemistry|  80|     P|        72|  2|\n",
      "|    Prachi|female|    Physics|  72|     P|        72|  3|\n",
      "|   Shruthi|Female|    Physics|  60|     P|        86|  1|\n",
      "|Vaishanavi|female|  chemistry|  86|     P|        70|  1|\n",
      "|Vaishanavi|female|Mathematics|  70|     P|        70|  2|\n",
      "|Vaishanavi|female|    Physics|  50|     P|        70|  3|\n",
      "|    mahesh|  Male|    Physics|  80|     P|        90|  1|\n",
      "|    mahesh|  Male|  chemistry|  67|     P|        90|  2|\n",
      "|    mahesh|  Male|Mathematics|  67|     P|        90|  3|\n",
      "|   shruthi|female|  Chemistry|  67|     P|        86|  1|\n",
      "|   shruthi|female|Mathematics|  52|     P|        86|  2|\n",
      "+----------+------+-----------+----+------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create rank within each group of name\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col,row_number\n",
    "\n",
    "windowdept = Window.partitionBy('name').orderBy(col('mark').desc())\n",
    "\n",
    "df2 = studf.withColumn('row',row_number().over(windowdept)).orderBy('name','row')\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-----------+----+------+----------+---+\n",
      "|      name|gender|    subject|mark|status|attendance|row|\n",
      "+----------+------+-----------+----+------+----------+---+\n",
      "|    Avanti|female|  Chemistry|  95|     P|        90|  1|\n",
      "|    Prachi|female|Mathematics|  90|     P|        72|  1|\n",
      "|   Shruthi|Female|    Physics|  60|     P|        86|  1|\n",
      "|Vaishanavi|female|  chemistry|  86|     P|        70|  1|\n",
      "|    mahesh|  Male|    Physics|  80|     P|        90|  1|\n",
      "|   shruthi|female|  Chemistry|  67|     P|        86|  1|\n",
      "+----------+------+-----------+----+------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get top N rows per group of name\n",
    "\n",
    "df3 = df2.filter(col(\"row\") <= 1)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-----------+----+------+----------+---+\n",
      "|      name|gender|    subject|mark|status|attendance|row|\n",
      "+----------+------+-----------+----+------+----------+---+\n",
      "|    Avanti|female|  Chemistry|  95|     P|        90|  1|\n",
      "|    Avanti|female|Mathematics|  78|     P|        90|  2|\n",
      "|    Avanti|female|    Physics|  77|     P|        90|  2|\n",
      "|    Prachi|female|Mathematics|  90|     P|        72|  1|\n",
      "|    Prachi|female|  chemistry|  80|     P|        72|  2|\n",
      "|    Prachi|female|    Physics|  72|     P|        72|  3|\n",
      "|   Shruthi|Female|    Physics|  60|     P|        86|  4|\n",
      "|Vaishanavi|female|  chemistry|  86|     P|        70|  1|\n",
      "|Vaishanavi|female|Mathematics|  70|     P|        70|  3|\n",
      "|Vaishanavi|female|    Physics|  50|     P|        70|  5|\n",
      "|    mahesh|  Male|    Physics|  80|     P|        90|  1|\n",
      "|    mahesh|  Male|  chemistry|  67|     P|        90|  3|\n",
      "|    mahesh|  Male|Mathematics|  67|     P|        90|  4|\n",
      "|   shruthi|female|  Chemistry|  67|     P|        86|  2|\n",
      "|   shruthi|female|Mathematics|  52|     P|        86|  5|\n",
      "+----------+------+-----------+----+------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create rank within each grop of subject\n",
    "\n",
    "windowdept = Window.partitionBy('subject').orderBy(col('mark').desc())\n",
    "\n",
    "df4 = studf.withColumn('row',row_number().over(windowdept)).orderBy('name','row')\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-----------+----+------+----------+---+\n",
      "|      name|gender|    subject|mark|status|attendance|row|\n",
      "+----------+------+-----------+----+------+----------+---+\n",
      "|    Avanti|female|  Chemistry|  95|     P|        90|  1|\n",
      "|    Prachi|female|Mathematics|  90|     P|        72|  1|\n",
      "|Vaishanavi|female|  chemistry|  86|     P|        70|  1|\n",
      "|    mahesh|  Male|    Physics|  80|     P|        90|  1|\n",
      "+----------+------+-----------+----+------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get top N rows per group of name\n",
    "\n",
    "df5 = df4.filter(col(\"row\") <= 1)\n",
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-----------+----+------+----------+---+\n",
      "|      name|gender|    subject|mark|status|attendance|row|\n",
      "+----------+------+-----------+----+------+----------+---+\n",
      "|    Avanti|female|  Chemistry|  95|     P|        90|  2|\n",
      "|    Avanti|female|Mathematics|  78|     P|        90|  4|\n",
      "|    Avanti|female|    Physics|  77|     P|        90|  4|\n",
      "|    Prachi|female|  chemistry|  80|     P|        72|  2|\n",
      "|    Prachi|female|    Physics|  72|     P|        72|  3|\n",
      "|    Prachi|female|Mathematics|  90|     P|        72|  5|\n",
      "|   Shruthi|Female|    Physics|  60|     P|        86|  2|\n",
      "|Vaishanavi|female|    Physics|  50|     P|        70|  1|\n",
      "|Vaishanavi|female|Mathematics|  70|     P|        70|  3|\n",
      "|Vaishanavi|female|  chemistry|  86|     P|        70|  3|\n",
      "|    mahesh|  Male|  chemistry|  67|     P|        90|  1|\n",
      "|    mahesh|  Male|Mathematics|  67|     P|        90|  2|\n",
      "|    mahesh|  Male|    Physics|  80|     P|        90|  5|\n",
      "|   shruthi|female|  Chemistry|  67|     P|        86|  1|\n",
      "|   shruthi|female|Mathematics|  52|     P|        86|  1|\n",
      "+----------+------+-----------+----+------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create rank within each grop of subject\n",
    "\n",
    "windowdept = Window.partitionBy('subject').orderBy(col('mark'))\n",
    "\n",
    "df6 = studf.withColumn('row',row_number().over(windowdept)).orderBy('name','row')\n",
    "df6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-----------+----+------+----------+---+\n",
      "|      name|gender|    subject|mark|status|attendance|row|\n",
      "+----------+------+-----------+----+------+----------+---+\n",
      "|    Avanti|female|  Chemistry|  95|     P|        90|  1|\n",
      "|    Prachi|female|Mathematics|  90|     P|        72|  1|\n",
      "|Vaishanavi|female|  chemistry|  86|     P|        70|  1|\n",
      "|    mahesh|  Male|    Physics|  80|     P|        90|  1|\n",
      "+----------+------+-----------+----+------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get top N rows per group of name\n",
    "\n",
    "df7 = df6.filter(col(\"row\") <= 1)\n",
    "df5.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
